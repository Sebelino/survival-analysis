---
title: "Survival Analysis: Take-home Exam"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

# AI disclosure

ChatGPT was used to review my solutions and for grammar and clarity checks.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "")
```

# A.1.

Let \(\lambda_1 = \lambda\exp(\beta x)\).
Then the proportional hazards model has a survival time function
of the form:

\begin{align*}
    & S(t|x) \\
    =& S_0(t)^{\exp(\beta x)} \\
    =& \exp(-\lambda t^k)^{\exp(\beta x)} \\
    =& \exp(-\lambda t^k\exp(\beta x)) \\
    =& \exp(-\lambda\exp(\beta x) t^k) \\
    =& \exp(-\lambda_1 t^k) \\
\end{align*}

which has the form of a Weibull distribution
with shape parameter $k$ and scale parameter
\(\lambda_1 = \lambda\exp(-k\tilde{\beta} x)\).

# A.2.

Let \(\lambda_2 = \lambda\exp(-k\tilde{\beta} x)\).
Then the accelerated survival time model has a survival time function
of the form:

\begin{align*}
    & S(t|x) \\
    =& S_0(t \exp(-\tilde{\beta} x)) \\
    =& \exp(-\lambda(t \exp(-\tilde{\beta} x))^k) \\
    =& \exp(-\lambda t^k \exp(-\tilde{\beta} x)^k) \\
    =& \exp(-\lambda t^k \exp(-k\tilde{\beta} x)) \\
    =& \exp(-\lambda\exp(-k\tilde{\beta} x) t^k) \\
    =& \exp(-\lambda_2 t^k ) \\
\end{align*}

which has the form of a Weibull distribution
with shape parameter $k$ and scale parameter
\(\lambda_2 = \lambda\exp(-k\tilde{\beta} x)\).

# A.3.

Proportional hazards model survival function:
\[\exp(-\lambda\exp(\beta x) t^k)\]
Accelerated survival time model survival function:
\[\exp(-\lambda\exp(-k\tilde{\beta} x) t^k)\]
We see that the survival functions are equal if
the log hazard ratio is related to the log time ratio like so:
\[\beta = -k\tilde{\beta}\]
Given that the shape parameter \(k\) is positive,
this means
a positive \(\beta\) implies a negative \(\tilde{\beta}\).

# B.1.

Let \(T\) be the survival time of an individual,
so that \(S(t) = P(T>t)\).

## a)

For individual \(i\),
we know that the event was observed in the interval \((u_i,v_i]\),
which means \(u_i < T_i \leq v_i\). Furthermore,
the event is only observed if \(T_i > t_i\), so we need to
condition on \(T_i>t_i\).
The likelihood contribution for a single data tuple \((t_i,u_i,v_i)\) is:
\begin{align*}
    & P(u_i < T_i \leq v_i \, | \, T_i > t_i) \\
    =& \frac{P(\{u_i < T_i \leq v_i\} \cap \{T_i > t_i\})}{P(T_i > t_i)} \\
    =& \frac{P(\max(t_i,u_i) < T_i \leq v_i)}{P(T_i > t_i)} \\
    =& \frac{P(u_i < T_i \leq v_i)}{P(T_i > t_i)} \\
    =& \frac{F_{T_i}(v_i)-F_{T_i}(u_i)}{P(T_i > t_i)} \\
    =& \frac{1-S(v_i)-(1-S(u_i))}{S(t_i)} \\
    =& \frac{S(u_i)-S(v_i)}{S(t_i)} \\
\end{align*}

Log-likelihood contribution for individual \(i\):
\begin{align*}
    & \ell_i \\
    =& \ln\frac{S(u_i)-S(v_i)}{S(t_i)} \\
    =& \ln(S(u_i) - S(v_i)) - \ln S(t_i) \\
\end{align*}

Log-likelihood contribution for \(n\) individuals:
\begin{align*}
    & \ell_{1:n} \\
    =& \ln\prod_{i=1}^n \frac{S(u_i)-S(v_i)}{S(t_i)} \\
    =& \sum_{i=1}^n \left(\ln(S(u_i) - S(v_i)) - \ln S(t_i)\right) \\
\end{align*}

## b)

Log-likelihood contribution for individual \(i\):
\begin{align*}
    & \ell_i \\
    =& \ln(S(u_i) - S(v_i)) - \ln S(t_i) \\
    =& \ln\left(S(u_i) - S(u_i)\exp\left(-\int_{u_i}^{v_i} h(t)dt\right)\right) - \ln S(t_i) \\
    =& \ln\left(S(u_i)\left(1 - \exp\left(-\int_{u_i}^{v_i} h(t)dt\right)\right)\right) - \ln S(t_i) \\
    =& \ln S(u_i) + \ln\left(1 - \exp\left(-\int_{u_i}^{v_i} h(t)dt\right)\right) - \ln S(t_i) \\
    =& \ln \exp\left(-\int_0^{u_i} h(t)dt\right) + \ln\left(1 - \exp\left(-\int_{u_i}^{v_i} h(t)dt\right)\right) - \ln \exp\left(-\int_0^{t_i} h(t)dt\right) \\
    =& -\int_0^{u_i} h(t)dt + \ln\left(1 - \exp\left(-\int_{u_i}^{v_i} h(t)dt\right)\right) +\int_0^{t_i} h(t)dt \\
    =& \ln\left(1 - \exp\left(-\int_{u_i}^{v_i} h(t)dt\right)\right) - \int_{t_i}^{u_i} h(t)dt
\end{align*}

<!-- TODO n individuals case as well? -->

# B.2.

```{r, message=FALSE, echo=FALSE}
library(survival)
```

According to the documentation [REF] and source code [REF]
for version `3.8-3` of the package,
the function takes the following arguments:

* `time`: Number.
* `time2`: Number.
* `event`: Either 0, 1, 2, 3, TRUE or FALSE.
* `type`: Any of the strings: `'right'`, `'left'`, `'interval'`, `'counting'`, `'interval2'`, `'mstate'`.
* `origin`: Number.

Let us assume that it is possible to express the tuple \((t_i,u_i,v_i)\)
using the `Surv` function.
Then it is possible to do so by
a function call of the form:
```{r, eval=FALSE}
Surv(time=a, time2=b, event=c, type=d, origin=e)
```
Since $t_i$, $u_i$, and $v_i$ are arbitrary numbers,
we cannot pass them to the function via the `event` or `type` arguments.
Hence, $t_i$, $u_i$, and $v_i$
can only be passed to the function using the
`time`, `time2`, and `origin` arguments.

Further, it is reasonable to presume that
$t_i$, $u_i$, and $v_i$ are passed to the function
via the `time`, `time2`, and `origin` arguments in a bijective manner.
That is, the `Surv` function is not implemented in a way such that,
for example, the data contained in the $t_i$ and $u_i$ values are cleverly encoded together so they can be passed using a single argument, e.g. `time`.

However, according to the documentation and source code,
the `origin` argument simply shifts the time scale,
by subtracting from `time` and `time2`.
Left truncation requires `type='counting'` which
does not allow for interval censoring.
On the other hand, interval censoring requires `type='interval'`
which does not allow for left truncation.
It is therefore not possible to use this argument to pass
information regarding left truncation or interval censoring.

Hence, we are left with only two arguments: `time` and `time2`
for passing the three values.
By the pigeonhole principle,
it is not possible to pass three values using only two arguments.
Thus, our initial assumption is incorrect.
It is not possible to express the tuple \((t_i,u_i,v_i)\)
using the `Surv` function.

<!-- TODO Argument can prolly be made more solid -->

# C.1.

\begin{align*}
    & P(T>t \,|\, T>t_0) \\
    =& \frac{P(\{T>t\} \cap \{T>t_0\})}{P(T>t_0)} \\
    =& \frac{P(T > \max(t_0,t))}{P(T>t_0)} \\
    =& \begin{cases}\frac{P(T > t)}{P(T>t_0)} \text{ if }t_0\leq t \\ \frac{P(T > t_0)}{P(T>t_0)} \text{ if }t_0>t\end{cases} \\
    =& \frac{P(T > t)}{P(T>t_0)}𝟙_{t_0\leq t} + \frac{P(T > t_0)}{P(T>t_0)}𝟙_{t_0> t} \\
    =& \frac{P(T > t)}{P(T>t_0)}𝟙_{t_0\leq t} + 𝟙_{t_0> t} \\
    =& \frac{P(T > t)}{P(T>t_0)}𝟙_{t_0\leq t} + 1-𝟙_{t_0\leq  t} \\
    =& \left(\frac{P(T > t)}{P(T>t_0)}-1\right)𝟙_{t_0\leq  t}+1 \\
    =& \left(\frac{S(t)}{S(t_0)}-1\right)𝟙_{t_0\leq  t}+1 \\
\end{align*}

If \(t_0\leq t\), the expression simplifies to:
\[P(T>t \,|\, T>t_0) = \frac{S(t)}{S(t_0)}\]

# C.2.

We know that \(Q(q) = S^{-1}(1-q)\) for any \(q\). Equivalently,
\(Q(1-q) = S^{-1}(1-(1-q)) = S^{-1}(q)\).
With this formula, and with \(t=Q(p\,|\,t_0)\) and assuming \(t_0\leq t\), we get:

\begin{align*}
    & P(T> t \,|\, T>t_0) = 1-p \\
    \Rightarrow& \frac{S(t)}{S(t_0)} = 1-p \\
    \Rightarrow& S(t) = (1-p)S(t_0) \\
    \Rightarrow& S(Q(p\,|\,t_0)) = (1-p)S(t_0) \\
    \Rightarrow& Q(p\,|\,t_0) = S^{-1}((1-p)S(t_0)) \\
    \Rightarrow& Q(p\,|\,t_0) = Q(1-(1-p)S(t_0))  \\
\end{align*}

<!-- Not accounting for t0>t -->

# C.3.

We can rewrite the previous formula for \(Q(p\,|\,t_0)\) using the CDF:
\[Q(p\,|\,t_0) = Q(1-(1-p)(1-F_T(t_0)))\]
Given \(T\sim \text{LogNormal}(\mu,\sigma^2)\), `plnorm(t0,mu,sigma)` computes
\(F_T(t_0)\), and `qlnorm(q,mu,sigma)` computes \(Q(q)\).

We can therefore compute \(Q(t|t_0)\) like so:

```{r}
p <- 0.4
t0 <- 2
mu <- 1
sigma <- 1.2

cdf_t0 <- plnorm(t0, meanlog=mu, sdlog=sigma)
prob <- 1-(1-p)*(1-cdf_t0)
qlnorm(prob, meanlog=mu, sdlog=sigma)
```

Thus:
\[Q(0.4\,|\,2) = Q(1-(1-0.4)(1-F_T(2))) \approx 4.2\]

<!-- Not accounting for t0>t -->

# C.4.

```{r}
#' @param n the number of random numbers
#' @param meanlog mean on the log scale
#' @param sdlog sd on the log scale
#' @param t0 left truncation time(s)
#' @return vector of random numbers drawn from a truncated log-normal distribution
rtrunc_lnorm = function(n, meanlog, sdlog, t0) {
    y = rlnorm(n, meanlog, sdlog)
    while (any(y<t0))
        y[y<t0] = rlnorm(n, meanlog, sdlog)[y<t0]
    y
}

p <- 0.4
t0 <- 2
mu <- 1
sigma <- 1.2
n <- 1e6

set.seed(7)
sample <- rtrunc_lnorm(n, mu, sigma, t0)
quantile(sample, probs = p)
```

With a sufficiently large sample size (\(n=10^6\)),
wee see that
`quantile` gives
us an empirical 40th percentile which is approximately equal to
our value in C3:
\[4.178294 \approx 4.171994\]

# D.1.

\[L(\boldsymbol{\beta}) = \prod_{i=1}^n \left(\frac{\exp(\mathbf{x}_i(t_i)^\top\boldsymbol{\beta})}{\sum_{j\in R(t_i)} \exp(\mathbf{x}_j(t_i)^\top\boldsymbol{\beta})}\right)^{\delta_i}\]

# D.2.

# D.3.

# D.4.

# E.1.

# E.2.

# E.3.

# E.4.

# F.1.

# F.2.


```{r, message=FALSE}
library(biostat3) # colon
library(dplyr)
```
